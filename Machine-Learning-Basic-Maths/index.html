<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/BlogPosting" >
    <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Machine Learning Basic Maths</title>
    <meta name="description" content="Technical blogs.">

    <!-- Google Authorship Markup -->
    <link rel="author" href="https://plus.google.com/+?rel=author">

    <!-- Social: Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@">
    <meta name="twitter:title" content="Machine Learning Basic Maths">
    <meta name="twitter:description" content="Technical blogs.">
    
    <meta property="twitter:image:src" content="https://abyte.stream/assets/img/blog-image.png">
    

    <!-- Social: Facebook / Open Graph -->
    <meta property="og:url" content="https://abyte.stream/Machine-Learning-Basic-Maths/">
    <meta property="og:title" content="Machine Learning Basic Maths">
    
    <meta property="og:image" content="https://abyte.stream/assets/img/blog-image.png">
    
    <meta property="og:description" content="Technical blogs.">
    <meta property="og:site_name" content="Sanjay Patel - Blogs">

    <!-- Social: Google+ / Schema.org  -->
    <meta itemprop="name" content="Machine Learning Basic Maths"/>
    <meta itemprop="description" content="Technical blogs.">
    <meta itemprop="image" content="https://abyte.stream/assets/img/blog-image.png"/>

    <!-- Favicon -->
    <link rel="shortcut icon" href="/assets/img/icons/favicon.ico" type="image/x-icon" />
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/assets/img/icons/apple-touch-icon.png" />
    <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/icons/apple-touch-icon-57x57.png" />
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/icons/apple-touch-icon-72x72.png" />
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/icons/apple-touch-icon-114x114.png" />
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/icons/apple-touch-icon-144x144.png" />
    <link rel="apple-touch-icon" sizes="60x60" href="/assets/img/icons/apple-touch-icon-60x60.png" />
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/img/icons/apple-touch-icon-120x120.png" />
    <link rel="apple-touch-icon" sizes="76x76" href="/assets/img/icons/apple-touch-icon-76x76.png" />
    <link rel="apple-touch-icon" sizes="152x152" href="/assets/img/icons/apple-touch-icon-152x152.png" />

    <!--amp page-->
    
        <link rel="amphtml" href="https://abyte.stream/amp/Machine-Learning-Basic-Maths.html">
    
    <!-- Windows 8 Tile Icons -->
    <meta name="application-name" content="Sanjay Patel Blog">
    <meta name="msapplication-TileColor" content="#0562DC">
    <meta name="msapplication-square70x70logo" content="smalltile.png" />
    <meta name="msapplication-square150x150logo" content="mediumtile.png" />
    <meta name="msapplication-wide310x150logo" content="widetile.png" />
    <meta name="msapplication-square310x310logo" content="largetile.png" />
    <!-- Android Lolipop Theme Color -->
    <meta name="theme-color" content="">

    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://abyte.stream/Machine-Learning-Basic-Maths/">
    <link rel="alternate" type="application/rss+xml" title="Sanjay Patel - Blogs" href="https://abyte.stream/feed.xml" />
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-1067793-4"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-1067793-4');
    </script>

</head>

    <body>
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-close" viewBox="0 0 805 1024"><path class="path1" d="M741.714 755.429q0 22.857-16 38.857l-77.714 77.714q-16 16-38.857 16t-38.857-16l-168-168-168 168q-16 16-38.857 16t-38.857-16l-77.714-77.714q-16-16-16-38.857t16-38.857l168-168-168-168q-16-16-16-38.857t16-38.857l77.714-77.714q16-16 38.857-16t38.857 16l168 168 168-168q16-16 38.857-16t38.857 16l77.714 77.714q16 16 16 38.857t-16 38.857l-168 168 168 168q16 16 16 38.857z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-google-plus" viewBox="0 0 951 1024"><path class="path1" d="M420 454.857q0 20.571 18.286 40.286t44.286 38.857 51.714 42 44 59.429 18.286 81.143q0 51.429-27.429 98.857-41.143 69.714-120.571 102.571t-170.286 32.857q-75.429 0-140.857-23.714t-98-78.571q-21.143-34.286-21.143-74.857 0-46.286 25.429-85.714t67.714-65.714q74.857-46.857 230.857-57.143-18.286-24-27.143-42.286t-8.857-41.714q0-20.571 12-48.571-26.286 2.286-38.857 2.286-84.571 0-142.571-55.143t-58-139.714q0-46.857 20.571-90.857t56.571-74.857q44-37.714 104.286-56t124.286-18.286h238.857l-78.857 50.286h-74.857q42.286 36 64 76t21.714 91.429q0 41.143-14 74t-33.714 53.143-39.714 37.143-34 35.143-14 37.714zM336.571 400q21.714 0 44.571-9.429t37.714-24.857q30.286-32.571 30.286-90.857 0-33.143-9.714-71.429t-27.714-74-48.286-59.143-66.857-23.429q-24 0-47.143 11.143t-37.429 30q-26.857 33.714-26.857 91.429 0 26.286 5.714 55.714t18 58.857 29.714 52.857 42.857 38.286 55.143 14.857zM337.714 898.857q33.143 0 63.714-7.429t56.571-22.286 41.714-41.714 15.714-62.286q0-14.286-4-28t-8.286-24-15.429-23.714-16.857-20-22-19.714-20.857-16.571-23.714-17.143-20.857-14.857q-9.143-1.143-27.429-1.143-30.286 0-60 4t-61.429 14.286-55.429 26.286-39.143 42.571-15.429 60.286q0 40 20 70.571t52.286 47.429 68 25.143 72.857 8.286zM800.571 398.286h121.714v61.714h-121.714v125.143h-60v-125.143h-121.143v-61.714h121.143v-124h60v124z"/></symbol></defs></svg>

        <header class="bar-header">
    <h1 class="logo">
        <a href="/"></a>
    </h1>
</header>
<div class="search-wrapper">
    <div class="search-form">
        <input type="text" class="search-field" placeholder="Search...">
        <svg class="icon-remove-sign"><use xlink:href="#icon-close"></use></svg>
        <ul class="search-results search-list"></ul>
    </div>
</div>

<div id="fade" class="overlay"></div>
<a id="slide" class="slideButton fade">
    <svg id="open" class="icon-menu"><use xlink:href="#icon-menu"></use></svg>
    <svg id="close" class="icon-menu"><use xlink:href="#icon-close"></use></svg>
</a>
<aside id="sidebar">
<nav id="navigation">
  <h2>MENU</h2>
  <ul>
    
      <li><a href="https://abyte.stream/">Home</a></li>
    
      <li><a href="https://abyte.stream/series">Series</a></li>
    
      <li><a href="https://abyte.stream/tags">Tags</a></li>
    
      <li><a href="https://abyte.stream/pretty-print/">Pretty Print</a></li>
    
      <li><a href="https://abyte.stream/sort-distinct/">Sort & Distinct</a></li>
    
    <li><a class="feed" href="https://abyte.stream/feed.xml" title="Atom/RSS feed">Feed</a></li>
  </ul>
</nav>
</aside>
<a id="search" class="dosearch">
    <svg class="icon-menu icon-search"><use xlink:href="#icon-search"></use></svg>
</a>

<header class="header-post" role="banner">
     <div class="content">
        
            <time itemprop="datePublished" datetime="2018-12-15T18:57:06-05:00" class="date">15 Dec 2018</time>
        
        <h1 class="post-title" itemprop="name">Machine Learning Basic Maths</h1>
        <p itemprop="description" class="subtitle"></p>
    </div>
</header>
        <section class="post">

            <section class="share">
            <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Ad Unit1 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-6254849299387322"
     data-ad-slot="2070150131"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
            </section>
            <article role="article" id="post" class="post-content" itemprop="articleBody">
                <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<p>This blog covers basic mathematics required for Machine learnig. There are many terms which we need to know before we can jump into Machine learning.</p>

<p>#Statistics in Mathematics
<strong>Data &amp; Frequency</strong>: <strong>Data</strong> be anything given as input, for ex, let’s say set of alphabets, <strong>frequency</strong> is defined as how many time each alphabets has appeared in the set. Percentage is defined as <script type="math/tex">\frac{frequency}{total\,items\,in\,set}</script></p>

<p><strong>Mean or Average or Population Mean</strong> - Is defined as sum of all elements divided by count of the elements. 
<script type="math/tex">\bar x = \frac{\sum X_i}{n}</script></p>

<p><strong>Sample Mean</strong> - Mean of the sample from whole population. It is represeted by <script type="math/tex">\\\bar x</script>, while population mean is represented by <script type="math/tex">\\\mu</script>.  It is used for symmetric dataset.
<strong>Median</strong> - Put all the number in ascending order and the element at half distnace is Median. Used for skewed dataset, doesn’t matter if few value are outlier. <br />
For ex:  Median or M or <script type="math/tex">\\\widetilde x</script> of 1,3,4,5,6,7,100,200 would be 5.5. Either middle or mean of middles.</p>

<p><strong>Mode</strong> - Is most frequent number. For example 1,1,1,2,100,101,103,100 is 1. As the 1 has occured maximum number of times.</p>

<p><strong>Quartile</strong> - The set is put in ascending order and devided into 4 quarter of equal width. For ex.
1,3,4,24,29,101,103  has first quartile as 3.5, second quartile/Median as 24 and third quartile as 115.</p>

<p><strong>Variance</strong> - Measure of being different then other. THere are three variance 1)Population variance 2) Sample variance 3)Alternate formula to calculate variance</p>

<p><strong>Population variance or just variance</strong> - Is formulated as average  of the square distance from mean. <script type="math/tex">\sigma ^2 = \frac{\sum _{i=1}^{N}(x_i-\mu)^2}{N}</script>.</p>

<p><strong>Standard deviation</strong> - Root of population variance is standard deviation. It gives normalized result against dataset. <script type="math/tex">\sigma = \sqrt\frac{\sum _{i=1}^{N}(x_i-\mu)^2}{N}</script></p>

<h3 id="permutation--combination">Permutation &amp; Combination</h3>
<p>Permutation is the count of number of ways which one particular Set can be arranged. The count should <strong>consider the order</strong>. For ex. S = {1,2,3} ca be arranged as {321,312,231,213,132,123}. So total number can be arranged as <script type="math/tex">3\times2\times 1\\n\times (n-1)\times(n-2)...\\n!</script></p>

<p>But what if number can be repeated.<br />
<script type="math/tex">3\times3\times 3\\n\times n\times n...\\n^n</script></p>

<p>What if the set is {1,2,3,4}, It will be <script type="math/tex">4!</script> and what if we need to pick only 2 out 4. n=4, r=2, n-r=2. The possible combination would be,<br />
<script type="math/tex">4\times3</script> = <script type="math/tex">4\times3\times\frac{2\times1}{2\times1}</script> 
<script type="math/tex">n\times(n-1)\times...(n-r)</script> = <script type="math/tex">n\times(n-1)\times...\frac{(n-r)\times(n-r-1)\times...1}{(n-r)\times(n-r-1)\times...1}</script> 
<script type="math/tex">P_r^n = \frac{n!}{(n-r!)}\\
\mathbf{If\,p_1,p_2..p_n\,are\,of\,same\,type}\\
P_r^n = \frac{n!}{(n-r!)p_1!p_2!..p_n!}\</script></p>

<p>For example, Flip coin 6 times, getting exactly 1 head {HTTTTT,THTTTT,TTHTTT,TTTHTT,TTTTHT,TTTTTH}, Order matters here so permuation henc 6!, but 5T are same so devide by 5!. In case of two heads, Group of two head and group of 4 tail hence, 6!/(4!2!) = 15.</p>

<p><strong>Combination</strong> is related to permutation, In this the order of number layed out is not important. For ex (1,2) and (2,1) are same. That mean combination is all the permutation deviled by permutation of r. In all the permutation we need to exclude sets which has same set of numbers in any order, let say Set of r can have r! possible permutation and there number of sets so for each set like (12,21) = 2!  = 2, one has to be excluded. Let’ say Set {1,2,3} and need to pick two number.<br />
<script type="math/tex">\require{cancel} P_2^3 = \frac{3!}{(3-2)!}= 6, \{32,31,23,21,13,12\}\\
C_2^3 = \frac{3!}{(3-2)!(2)!}= 3, \{32,31,\cancel{23},21,\cancel{13},\cancel{12}\}\\
C_r^n = \frac{n!}{(n-r!)r!} = \frac{P_r^n}{r!}\\
C_r^n\subseteq P_r^n\subseteq n! \subset n^n</script></p>

<p>In case there are multiple groups of same type g<sub>1</sub>,g<sub>2</sub>..g<sub>n</sub> and every we need r<sub>1</sub>,r<sub>2</sub>..r<sub>n</sub> number from each group respectively. The combination would be <script type="math/tex">C_{r_1}^{g_1}\times C_{r_2}^{g_2}\times..C_{r_n}^{g_n},</script><br />
For example a comity 3 people of 1 man and 2 women from a group 2 men and 3 women has to formed. M1,M2 and W1,W2,W3. Picking them in any order doesn’t matter so here commutaion has to be calculate. 2C1 and 3C2 = 6.</p>

<h3 id="probability">Probability</h3>
<p>Probability is a measure of how likely an event is going to happen from given set of event. For example. {1,2,3,4,6} are equally likely outcome of a dice. Then probability of coming to in a dice roll would be 1 out of 6. Probability of dice showing number 2.
<script type="math/tex">P(2) = \frac{1}{6},\\ P(x) = \frac{count\,of(event\,x)}{total\,count\,of\,all\,event}\\P(x+y) = \frac{count\,of\,event\,x+y}{count\,of\,all\,events}</script>.</p>

<p><strong>Probability in relation to probability</strong> Lets say A is event of 1 and 4 coming on dice and B is event {1,3,4} coming on dice. Interset of A and B is {1,4}
<script type="math/tex">P(A) = \frac{2}{6},\;P(B) = \frac{3}{6};\\
P(AUB) = P(A)+P(B)-P(A\cap B )  = \frac{1}{3}+\frac{1}{2}-\frac{2}{6} = \frac{1}{2}</script></p>

<p>If A and be are **independent ** A is dice and B is deck getting 1 on dice and an spades ace on dec is
<script type="math/tex">P(A\cap B) = P(A).P(B) = \frac{1}{6}\cdot\frac{1}{52} = \frac{1}{312}</script></p>

<p><strong>Conditional probability on Dependent event</strong> Dependent event are the one which affect the event space for next event. For example in a deck probability of getting Ace is 1/13 and then you put that Ace aside the card deck size is now 51, now the probability of getting ace is 3/51. Here A has affected the event space for B. So we can write P(A) then P(B) is,<br />
<script type="math/tex">P(A\,and\,B) or P(A\cap B) = P(A).P(B|A)\ = P(B).P(A|B)\;or\\
P(B|A) = \frac {P(A\,and\,B)}{P(A)}</script></p>

<p>Where P(B|A) can be defined as P(B) if P(A) has already occurred. P(B and A) are calculate over two dice throw, while P(B|A) is probability of second dice throw. Extend to third variable.<br />
<script type="math/tex">P(A|B,C)=\frac{P(A\cap B\cap C)}{P(B\cap C)}</script></p>

<p><strong>Random Variable</strong> - Random variable is possible outcome of any event. Let’s say in a particular match how many goals will be made, it can be 1 or 4 or 6 or any number. This is discrete and can be counted and has some interval. Set containing 0 to 100 is discrete, but different floating values between is infinite/uncountable. Thing which can’t be counted are <strong>continuos random variable</strong> and which can be counted are discrete. Continuos value can be measure but not counted for example volume.</p>

<p><strong>Probability distribution</strong> - Do not relate this with single probability ie (probability of getting 4 in dice.). Think it as sheet where first column is possible outcomes and second column is probability of that outcome. In this case the probability of each possible outcome is different. Fox ex. Let there are some event E1, E2 ..En from Sample Space S. And let X be function over combination of probabilities over multiple E. For ex. Flip coin three times and X is count H in this sample space. X will variate from 0 to 3.
X=0 {TTT} - 1, X=1 {HTT, THT, TTH} - 3, X=2 {HHT,HTH,THH} -3, X=3 {HHH} - 1.
<script type="math/tex">X\,be\,{x_1,x_2,x..}\; then\\P(x_1)+P(x_2)+P(x_3)+... = 1 = \sum_{i=0}^{n}p(x_i)</script></p>

<p><strong>Probability Mass function</strong> - Mass function comes into picture when the values are descrete and probability weight calculate by sum, in contrast to PDF which is intergral.
<script type="math/tex">pX(x) ≥ 0\;and\;\sum_x pX(x) = 1</script></p>

<p><strong>Probability Density Function</strong> - In a set of continuos event probability normally measure between two points and the area under two defines the probability density function. The entire area is calculated as one. PDF exist only for continuos variable and the area under two interval is the probability. Let’s say x is random variable and f(x) is the probability of the x variable then.
<script type="math/tex">P(a\leq x \leq b) = \int_a^b f(x)dx \\
\int_{-\infty}^{+\infty} f(x)dx = 1</script></p>
<ul>
  <li>Probability of normally distribute function looks like bell shaped and has fixed are under two interval.</li>
  <li>Conitnous functions are calculated by integral while discrete with summation.
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths5.JPG" alt="" /></li>
</ul>

<p><strong>Probability Commutative function</strong> - Probability of being equal to or less then x, F(x)=P(X≤x)</p>

<p><strong>Random Variable X - μ</strong> - Average of probability random variable ie function over sample space. 
<strong>Mean or Expected value over discrete function</strong></p>

<script type="math/tex; mode=display">E(X)=\mu=\sum_{i-1}^nx_ip(x_i)\\
\mathbf{Continous \, variable}\\
E(X)=\mu=\int_{-\infty}^{+\infty}x_if(x)dx\\
\mathbf{Lotus-Law\,of\,Unconscious\,Statistician}\\
E(g(x))=\sum_{\infty}g(x)P(X=x)\\
E(g(x))=\int_{-\infty}^{+\infty}g(x)f(x)dx\\
\mathbf{Variance\,of\,random\,variable}\\
Var(X)=\sigma^2=E{(X-\mu)}^2=\sum_{i-1}^n{(x_i-\mu)^2}p(x_i) = E((X-E(X))^2) = E(X^2)-(E(X))^2\\\\
\mathbf{Standard\,deviation}
SD(X)=\sqrt{Var(X)}=\sigma=\sqrt{\sum_{i-1}^n{(x_i-\mu)^2}p(x_i)}=\sqrt{\sum_{i-1}^nx_i^2p(x_i)}\\</script>

<p><strong>Standard deviation</strong> - How far the numbers are from mean on average, think of population having lot of small numbers and then some big numbers so mean doesn’t in middle but at the one end. In this case mean and standard deviation will be far.
<strong>Covariance</strong> - Measures tendency of x and y deviate from their mean in same or opposite direction at same time.
<script type="math/tex">cov(x,y)=  \sum_ip(x_i,y_i)(x_i-\mu_x)(y_i-\mu_x)\\
\mathbf comapre\,to\,actual\,covariance(not\,in\,probability\,space)\\
\sum_ip(x_i)=\frac{1}{N-1} \sum_1^n \\
cov(x,y)=  \frac{1}{N-1}\sum_1^n(x_i-\mu_x)(y_i-\mu_x)</script>
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths6.JPG" alt="" />
<strong>Correlation</strong> - Perason’s correlation coefficient is coveriance normalized by standard deviations of variables.
<script type="math/tex">corr(x,y)=\frac{cov(x,y)}{\sigma_x\sigma_y}</script></p>

<p><strong>Mean or Expected value over continuos function</strong>
<script type="math/tex">E(X) = \int_{x=a\to b}xp(x)</script></p>

<p><strong>Bayes Theorem</strong> - Let A<sub>1</sub>, A<sub>2</sub>,A<sub>3</sub>..A<sub>n</sub> are sample set out of S where all including form S. Let B is another set from S, since it is part of S it definately form out of parts of A’s. Hence,<br />
B = (B ∩ A<sub>1</sub>)U(B ∩ A<sub>1</sub>)..U(B ∩A<sub>n</sub>) and we can write.
<script type="math/tex">P(A_k|B) = \frac{P(A_k\cap B)}{[P(A_1\cap B)+P(A_2\cap B)+..P(A_n\cap B)]}\\
Using\;P( A_k \cap B ) = P( A_k )P( B | A_k )\\
P( A_k | B ) =  	\frac{P( A_k ) P( B | A_l )}{[ P( A_1 ) P( B | A_1 ) + P( A_2 ) P( B | A_2 ) + . . . + P( A_n ) P( B | A_n ) ]}</script> 
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths7.JPG" alt="" /></p>

<h3 id="discrete-distribution">Discrete Distribution</h3>
<p><strong>Bernoulli Trials</strong> - Trials which answers only in two values, such yes/no, 0/1, head/tail etc. Such that <script type="math/tex">p=\frac12\;and\; q=1-p=\frac12</script>.</p>

<p><strong>Bernoulli Distribution</strong> - A sheet with with column1 as possible outcomes as 0 and 1 and coloumn2 as there probability. For ex, p = 0.15 and q= 0.85.
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths9.JPG" alt="" />
<script type="math/tex">E(X) = 0.q - 1.p = p\\
V(X) = E(p^2)-E(p)^2 = p-p^2</script>.</p>

<p><strong>Binomial Distribution</strong> - Here we talk about Bernoulli sample space. Let say function variable X is times we get Head and call it S and other is F. Flip 3 times (SSS,SST,STS,STT,TSS,TST,TTS,TTT). p is success probability and q is failure.</p>

<table>
  <thead>
    <tr>
      <th>X</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>P</td>
      <td>q<sup>3</sup></td>
      <td>3q<sup>2</sup>p</td>
      <td>3p<sup>2</sup>q</td>
      <td>p<sup>3</sup></td>
    </tr>
  </tbody>
</table>

<p><script type="math/tex">P(S)=q^3+3q^2p+3qp^2+p^3=1\\
\sum_{i=0}^nP(x_i) = \sum_{i=0}^nC_x^nq^{n-x}p^x=1\\
\mu=np\;,Var(X)=npq</script>
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths11.JPG" alt="" /></p>

<p><strong>Hypergeometric Distribution</strong> - Binomial but sample space reduced due to last event, for ex. draw colored ball from bag starting with equal probability, but do not place the ball back which reduces the sample space.<br />
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths12.JPG" alt="" /></p>

<p><strong>Uniform distribution</strong> - Fair dice role has 6 possible outcome and each has probability of 1/6. Since 1 is total probaility, area = width*height = f(x)(b-a) = 1; f(x) = 1/(b-a)
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths13.JPG" alt="" />
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths10.JPG" alt="" />
<script type="math/tex">\mu= \int_a^bxf(x)dx = \int_a^bx\frac{1}{b-a}dx = \frac{a+b}{2}\\
Var(X)=\frac{(b-a)^2}{12}</script></p>

<p><strong>Poisson Distribution</strong> - Type of binomial but rate defined by λ, The distribution when you know the constant rate of event over time or space. For ex. 50 email per hours or 22 trees per kilometer etc. Second thing the event are independent. For ex, 20 call per minute, then 0.33 call per second. Every second either call can come (0.33) or not(0.66). Let λ	be probability of call per minute, divide that in n=60 interval then probability of on slice of n is p=λ/n and q=1-λ/n.
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths14.JPG" alt="" />
<script type="math/tex">P(X=x) = C_x^np^xq^{n-x} =  \frac{n!}{(n-x)!x!}{\frac{\lambda}{n}}^x\left({1-\frac{\lambda}{x}}^{n-x}\right)=\frac{\lambda^xe^{-\lambda}}{x!} \\
E(X)=\mu=\lambda,\;Var(X)=\mu=\lambda</script></p>

<p><strong>Negative Binomial Distribution</strong> - Number of failure before you get specific number of success. In contrast to Binomial, how many success after x trials. this is how many failures needed to get k successes and this gives how many trials. let k be number of successes in x trial then x-k is number of failure.</p>

<p><strong>Geometric Distribution</strong> - Type of negative Binomial where you are interested to get first success after r failures. Number of trial becomes x = r+1. We are looking at kth trial which is success.
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths15.JPG" alt="" />
<script type="math/tex">P(X=k) = (1-p)^{k-1}p\\
E(X)=\mu = 1/p,\;P(Failure) = \frac{(1-p)}{p}\\
Var(X) = \frac{1-p}{p^2}</script></p>

<h3 id="continuos-distribution">Continuos Distribution</h3>

<p><strong>Normal Distribution</strong> - Distribution where mean, mode and median coincide. It is bell shaped, there are equal exactly half of the value on left and right side. 
<script type="math/tex">f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\\
E(X)=\mu,\;Var(X)=\sigma^2</script>
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths16.JPG" alt="" />
Normal distribution is not related to pro</p>

<p><strong>Central Limit Theorem</strong>- CLT (center, shape and spread), states even if we take an uneven distribution and take sample from it for n times, find the mean of each sample, start putting mean in buckets, the graph formed due to this filling will be more like normal distribution.<strong>Mean of sample means</strong> distribution will depict mean of populatiom.<strong>Stanadard Error</strong> of population will be standard deviation of distribution sample means.
<script type="math/tex">SE = \frac{\sigma}{\sqrt{N}}</script></p>

<p><strong>Exponential Distribution</strong> - It is mix of poisson where we have rate, like calls per minute and geometric where we are interested in wait time of next call or how many failure before next success. <strong>Weibull</strong> is counterpart of exponential, time to failure. Ex. Machine failure time when we know rate.
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths17.JPG" alt="" />
<script type="math/tex">F(x) = \lambda e^{-\lambda x}\\
E(X)=\mu = 1/\lambda,\\
Var(X) = \frac{1}{\lambda^2}</script></p>

<h2 id="calculus">Calculus</h2>
<p>How function changes over times(<strong>derivatives/by differentiation</strong>), how they accumulate over time period(<strong>integral/ by integration</strong>).</p>

<h3 id="derivative">Derivative</h3>
<p>It cabe defined in two ways.</p>
<ul>
  <li>In geometry - slope of line at specific point ie, y=mx+b, m becomes slope.</li>
  <li>In physics - Rate changes at instant.</li>
</ul>

<p><strong>In Geometry</strong><br />
The slope of line defined by following formula in between any two points. 
<script type="math/tex">Slope = m = \frac{y_1-y_2}{x_1-x_2}= \frac{f(x_1)-f(x_2)}{x_1-x_2}</script>
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths1.JPG" alt="!img" /></p>

<p>Here we talk about two point if two points are very close such that <script type="math/tex">x_1-x_2 \to 0</script>, here derivatives comes for rescue. The derivative formula.
<script type="math/tex">\Delta x= x_1-x_2 =h\\
\frac{d}{dx}f(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}\\
\mathbf{Ex}\;f(x) = x^2\\
\frac{d}{dx}f(x)=\lim_{h\to0}\frac{{(x+h)}^2-x^2}{h}=\lim_{x\to0}2x+h = 2x</script></p>

<p>Derivatives are used in optimization problems of machine learning. It helps us to determine to increase or decrease weights in order to achieve maximum or minimum output in  gradient decedent.</p>

<p><strong>Chain rule</strong>: <script type="math/tex">\frac{df}{dx}=\frac{dh}{dg}\frac{⋅dg}{dx}\\
\mathbf Ex:\; f(x) = h(g(x))\, where\, g(x)=x^2\,and\,h(x)=x^3\\
f(x) = (x^2)^3, g'(x)=2x, h'(x)=3x^2\\
f'(x)=h'(x).g'(x)= 3(x^2)^2.2x=6x^5</script></p>

<p>The reason we put double square as for h(x) was derived over g(x) where x = x<sup>2</sup>. The same goes with multiple chains.</p>

<h3 id="gradient">Gradient.</h3>
<p>Gradient is a variable which hold partial derivative multivariable function. Partial derivate of function is keeping all other variable constant and find derivative over one. 
<script type="math/tex">f(x,y,z)=2z^3x^2y^7\\
\nabla f(x,y,x)=\begin{bmatrix}\frac{df}{dx}\\\frac{df}{dy}\\\frac{df}{dz}\end{bmatrix}=\begin{bmatrix}4z^3xy^7\\14z^3x^2y^6\\6z^2x^2y^7\end{bmatrix}</script></p>

<p><strong>Direction Derivative</strong> - While trying for minimum maximum by variating a single variable and keeping others constant we can also apply directional derivative in order tocheck what would happen if take a small nudhe to our current slope, what if in place of north go south. 
<script type="math/tex">\vec v.\nabla f(x,y,x)=\begin{bmatrix}2\\3\\-1\end{bmatrix}.\begin{bmatrix}\frac{df}{dx}\\\frac{df}{dy}\\\frac{df}{dz}\end{bmatrix}</script></p>

<ul>
  <li>Gradient always points to the direction of greatest increasae or decrease of a function.</li>
  <li>Gradient reaches to zero in case of maxima and minima.</li>
</ul>

<h3 id="integrals">Integrals</h3>
<p>Integrals can be defined as how much accumulated over time, in other terms how much area is covered under a slope between two points.
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths2.JPG" alt="" /></p>

<p><script type="math/tex">F(x) = \int_a^b f(x)dx \\
Areas(a,b) = F(b)-F(a)= \int_0^b f(x)dx-\int_0^a f(x)dx</script>
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths3.JPG" alt="" /></p>

<p><strong>Important Formula</strong><br />
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths4.JPG" alt="" /></p>

<p><strong>Common Usage of Integral</strong></p>
<ul>
  <li>Probability under PD - <script type="math/tex">\int_{-\infty}^{+\infty} p(x)dx=1</script>.</li>
  <li>Expected Value - <script type="math/tex">\int_{-\infty}^{+\infty} xp(x)</script>.</li>
  <li>Variance - <script type="math/tex">\sigma^2=\int_{-\infty}^{+\infty} (x-\mu)^2p(x)</script>.</li>
</ul>

<h2 id="linear-algebra">Linear Algebra</h2>
<h3 id="vector">Vector</h3>
<p>Vector is variable stores direction and it’s magnitude from center. In 2D, left 7 and up 2 gives direction m = -2/7 and magnitude as well. It can be stored in 1D array/matrix column or raw anything [-7 2]. It is denoted mostly by bold italic latter with arrow on top. <script type="math/tex">\vec v = (a_x,a_y)\\</script>
<img src="/assets/2019-06-12-Machine-Learning-Basic-Maths8.JPG" alt="" />
<script type="math/tex">\mathbf{magnitude} = |v|(not\,absolute)=||v||= \sqrt{x^2+y^2}\\
x=rcos\theta,\; y=rsin\theta\\
r=\sqrt{x^2+y^2},\; \theta = tan^{-1}(y/x)\\ 
\begin{bmatrix}a\\b\end{bmatrix}+\begin{bmatrix}c\\d\end{bmatrix}=\begin{bmatrix}a+c\\b+d\end{bmatrix}\\
\begin{bmatrix}a\\b\end{bmatrix}-\begin{bmatrix}c\\d\end{bmatrix}=\begin{bmatrix}a-c\\b-d\end{bmatrix}\\
\begin{bmatrix}a\\b\end{bmatrix}/\begin{bmatrix}c\\d\end{bmatrix}=\begin{bmatrix}a/c\\b/d\end{bmatrix}\\
\mathbf{Hadamard\,product}\begin{bmatrix}a\\b\end{bmatrix}\odot\begin{bmatrix}c\\d\end{bmatrix}=\begin{bmatrix}a.c\\b.d\end{bmatrix}\\</script></p>

<p>Vector need not to be scaler only they can be a function. Let say x,y is the point on the plane and if it is applied to a vector f(x) = x<sup>2</sup>. In this case depending on X vector value will variate.</p>

<p><strong>Dot product</strong> - Multiplication
<script type="math/tex">% <![CDATA[
A = \begin{bmatrix}a\\b\end{bmatrix}, B = \begin{bmatrix}c&d\end{bmatrix}\\
A.B = ac+bd\\
\vec a.\vec b = |a||b|cos\theta,\; theta\,is\,angle\,between\,\vec a\; \vec b %]]></script></p>

<p><strong>Projection</strong> - <script type="math/tex">\vec b</script> can make projectopn over <script type="math/tex">\vec a</script> it is the base of the triangle formed by a and b. 
<script type="math/tex">proj_ab=\frac{\vec a\vec b}{|\vec a|^2}\vec a</script></p>

<h3 id="matrix">Matrix</h3>
<p>Matrix is rectangular grid to store different variable or scaler numbers. You can visualize it as 2D array. Addition and substraction on mattrix over scaller values applies to all the elements and if it is added or substracted by another matrix then each element will be added or substracted on each element of other matrix. Multiplication follows the same concept as Dot product and devision is not straight forward it is calculate by multiplying with inverse of the matrix. Division is only possible if divident determinant is non-zero and is a sqaure matrix. 
<script type="math/tex">% <![CDATA[
\begin{bmatrix}a&b\\c&d\end{bmatrix}\pm1=\begin{bmatrix}a\pm1&b\pm1\\c\pm1&d\pm1\end{bmatrix}\\
\begin{bmatrix}a&b\\c&d\end{bmatrix}\times\div1=\begin{bmatrix}a\times\div1&b\times\div1\\c\times\div1&d\times\div1\end{bmatrix}\\
\begin{bmatrix}a&b\\c&d\end{bmatrix}.\begin{bmatrix}w&x\\y&z\end{bmatrix}=\begin{bmatrix}aw+by&ax+bz\\cw+dy&cz+dz\end{bmatrix}\\
A*A^{-1}=I\\
AB\neq BA\\
A/B=AB^{-1}\neq B^{-1}A\\
(AB)^T=B^TA^T %]]></script></p>

            </article>

            <section class="share">
    <h3>Share</h3>
    <a aria-label="Share on Twitter" href="https://twitter.com/intent/tweet?text=&quot;&quot;%20https://abyte.stream/Machine-Learning-Basic-Maths/%20via%20&#64;&hashtags="
    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Share on Twitter">
        <svg class="icon icon-twitter"><use xlink:href="#icon-twitter"></use></svg>
    </a>
    <a aria-label="Share on Facebook"href="https://www.facebook.com/sharer/sharer.php?u=https://abyte.stream/Machine-Learning-Basic-Maths/"
    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;" title="Share on Facebook">
        <svg class="icon icon-facebook"><use xlink:href="#icon-facebook"></use></svg>
    </a>
    <a aria-label="Share on Google Plus" href="https://plus.google.com/share?url=https://abyte.stream/Machine-Learning-Basic-Maths/"
    onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;" title="Share on Google+">
        <svg class="icon icon-google-plus"><use xlink:href="#icon-google-plus"></use></svg>
    </a>
</section>
            <section class="share">
                <div class="fb-comments" data-href="https://abyte.stream/Machine-Learning-Basic-Maths/"></div>
            </section>
            <section class="author" itemprop="author">
    <div class="details" itemscope itemtype="http://schema.org/Person">
        <img itemprop="image" class="img-rounded" src="/assets/img/blog-author.jpg" alt="">
        <p class="def">Author</p>
        <h3 class="name">
            <a itemprop="name" href="https://plus.google.com/+/posts">Sanjay Patel</a>
        </h3>
        <p class="desc">Developer at IBM</p>
        <p><a itemprop="email" class="email" href="mailto:sanjaypatel2525@yahoo.com">sanjaypatel2525@yahoo.com</a></p>
        <!--<p><a itemprop="github" class="github" href="https://github.com/">github.com/</a></p>-->
    </div>
</section>

            <footer>
    <p>Made with <a href="http://jekyllrb.com/" target="_blank">Jekyll</a></p>
</footer>
<script src="/assets/js/main.js"></script>
            <div id="fb-root"></div>
        </section>
    </body>
    
    <script>(function(d, s, id) {
        var js, fjs = d.getElementsByTagName(s)[0];
        if (d.getElementById(id)) return;
        js = d.createElement(s); js.id = id;
        js.src = "//connect.facebook.net/en_GB/all.js#xfbml=1&appId=207343132703435";
        fjs.parentNode.insertBefore(js, fjs);
        }(document, "script", "facebook-jssdk"));</script>
</html>
