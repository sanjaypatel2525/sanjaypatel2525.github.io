<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/BlogPosting" >
    <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Machine Learning with Tensor Flow.</title>
    <meta name="description" content="Technical blogs.">

    <!-- Google Authorship Markup -->
    <link rel="author" href="https://plus.google.com/+?rel=author">

    <!-- Social: Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@">
    <meta name="twitter:title" content="Machine Learning with Tensor Flow.">
    <meta name="twitter:description" content="Technical blogs.">
    
    <meta property="twitter:image:src" content="/assets/img/blog-image.png">
    

    <!-- Social: Facebook / Open Graph -->
    <meta property="og:url" content="/Machine-Learning-TensorFlow/">
    <meta property="og:title" content="Machine Learning with Tensor Flow.">
    
    <meta property="og:image" content="/assets/img/blog-image.png">
    
    <meta property="og:description" content="Technical blogs.">
    <meta property="og:site_name" content="Sanjay Patel - Blogs">

    <!-- Social: Google+ / Schema.org  -->
    <meta itemprop="name" content="Machine Learning with Tensor Flow."/>
    <meta itemprop="description" content="Technical blogs.">
    <meta itemprop="image" content="/assets/img/blog-image.png"/>

    <!-- Favicon -->
    <link rel="shortcut icon" href="/assets/img/icons/favicon.ico" type="image/x-icon" />
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/assets/img/icons/apple-touch-icon.png" />
    <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/icons/apple-touch-icon-57x57.png" />
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/icons/apple-touch-icon-72x72.png" />
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/icons/apple-touch-icon-114x114.png" />
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/icons/apple-touch-icon-144x144.png" />
    <link rel="apple-touch-icon" sizes="60x60" href="/assets/img/icons/apple-touch-icon-60x60.png" />
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/img/icons/apple-touch-icon-120x120.png" />
    <link rel="apple-touch-icon" sizes="76x76" href="/assets/img/icons/apple-touch-icon-76x76.png" />
    <link rel="apple-touch-icon" sizes="152x152" href="/assets/img/icons/apple-touch-icon-152x152.png" />

    <!--amp page-->
    
        <link rel="amphtml" href="/amp/Machine-Learning-TensorFlow.html">
    
    <!-- Windows 8 Tile Icons -->
    <meta name="application-name" content="Sanjay Patel Blog">
    <meta name="msapplication-TileColor" content="#0562DC">
    <meta name="msapplication-square70x70logo" content="smalltile.png" />
    <meta name="msapplication-square150x150logo" content="mediumtile.png" />
    <meta name="msapplication-wide310x150logo" content="widetile.png" />
    <meta name="msapplication-square310x310logo" content="largetile.png" />
    <!-- Android Lolipop Theme Color -->
    <meta name="theme-color" content="">

    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="/Machine-Learning-TensorFlow/">
    <link rel="alternate" type="application/rss+xml" title="Sanjay Patel - Blogs" href="/feed.xml" />
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script src="/assets/js/lazysizes.min.js" async=""></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-1067793-4"></script>
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-1067793-4');
    </script>

</head>

    <body>
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-close" viewBox="0 0 805 1024"><path class="path1" d="M741.714 755.429q0 22.857-16 38.857l-77.714 77.714q-16 16-38.857 16t-38.857-16l-168-168-168 168q-16 16-38.857 16t-38.857-16l-77.714-77.714q-16-16-16-38.857t16-38.857l168-168-168-168q-16-16-16-38.857t16-38.857l77.714-77.714q16-16 38.857-16t38.857 16l168 168 168-168q16-16 38.857-16t38.857 16l77.714 77.714q16 16 16 38.857t-16 38.857l-168 168 168 168q16 16 16 38.857z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-google-plus" viewBox="0 0 951 1024"><path class="path1" d="M420 454.857q0 20.571 18.286 40.286t44.286 38.857 51.714 42 44 59.429 18.286 81.143q0 51.429-27.429 98.857-41.143 69.714-120.571 102.571t-170.286 32.857q-75.429 0-140.857-23.714t-98-78.571q-21.143-34.286-21.143-74.857 0-46.286 25.429-85.714t67.714-65.714q74.857-46.857 230.857-57.143-18.286-24-27.143-42.286t-8.857-41.714q0-20.571 12-48.571-26.286 2.286-38.857 2.286-84.571 0-142.571-55.143t-58-139.714q0-46.857 20.571-90.857t56.571-74.857q44-37.714 104.286-56t124.286-18.286h238.857l-78.857 50.286h-74.857q42.286 36 64 76t21.714 91.429q0 41.143-14 74t-33.714 53.143-39.714 37.143-34 35.143-14 37.714zM336.571 400q21.714 0 44.571-9.429t37.714-24.857q30.286-32.571 30.286-90.857 0-33.143-9.714-71.429t-27.714-74-48.286-59.143-66.857-23.429q-24 0-47.143 11.143t-37.429 30q-26.857 33.714-26.857 91.429 0 26.286 5.714 55.714t18 58.857 29.714 52.857 42.857 38.286 55.143 14.857zM337.714 898.857q33.143 0 63.714-7.429t56.571-22.286 41.714-41.714 15.714-62.286q0-14.286-4-28t-8.286-24-15.429-23.714-16.857-20-22-19.714-20.857-16.571-23.714-17.143-20.857-14.857q-9.143-1.143-27.429-1.143-30.286 0-60 4t-61.429 14.286-55.429 26.286-39.143 42.571-15.429 60.286q0 40 20 70.571t52.286 47.429 68 25.143 72.857 8.286zM800.571 398.286h121.714v61.714h-121.714v125.143h-60v-125.143h-121.143v-61.714h121.143v-124h60v124z"/></symbol></defs></svg>

        <header class="bar-header">
    <h2 class="logo">
        <a href="/"></a>
    </h2>
</header>
<div class="search-wrapper">
    <div class="search-form">
        <input type="text" class="search-field" placeholder="Search...">
        <svg class="icon-remove-sign"><use xlink:href="#icon-close"></use></svg>
        <ul class="search-results search-list"></ul>
    </div>
</div>

<div id="fade" class="overlay"></div>
<a id="slide" class="slideButton fade">
    <svg id="open" class="icon-menu"><use xlink:href="#icon-menu"></use></svg>
    <svg id="close" class="icon-menu"><use xlink:href="#icon-close"></use></svg>
</a>
<aside id="sidebar">
<nav id="navigation">
  <h2>MENU</h2>
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/series">Series</a></li>
    
      <li><a href="/tags">Tags</a></li>
    
      <li><a href="/pretty-print/">Pretty Print</a></li>
    
      <li><a href="/sort-distinct/">Sort & Distinct</a></li>
    
    <li><a class="feed" href="/feed.xml" title="Atom/RSS feed">Feed</a></li>
  </ul>
</nav>
</aside>
<a id="search" class="dosearch">
    <svg class="icon-menu icon-search"><use xlink:href="#icon-search"></use></svg>
</a>

<header class="header-post" role="banner">
     <div class="content">
        
            <time itemprop="datePublished" datetime="2018-12-13T18:57:06-05:00" class="date">13 Dec 2018</time>
        
        <h1 class="post-title" itemprop="name">Machine Learning with Tensor Flow.</h1>
        <p itemprop="description" class="subtitle"></p>
    </div>
</header>
        <section class="post">

            <section class="share">
            <!-- Ad Unit1 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-6254849299387322"
     data-ad-slot="2070150131"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
            </section>
            <article role="article" id="post" class="post-content" itemprop="articleBody">
                <p>TensorFlow API is built by google and mainly deals with neural network but support other APIs as well such as scikit learn to one liner ML models.
<img src="/assets/2019-08-21-Machine-Learning-TensorFlow1.png" alt="" class="lazyload" /></p>

<h3 id="tf-1-vs-2">TF 1 vs 2</h3>
<ul>
  <li>Session and placeholder is removed by tf.function</li>
</ul>

<h3 id="tf-estimator">TF estimator</h3>
<p>It is library which hold all high level ML algorithm for ex. You can create your own estimator by extending <strong>tf.estimator.Estimator</strong> or just use predefined estimator, such as 
<strong>tf.estimator.DNNClassifier</strong> for deep models that perform multi-class classification.
<strong>tf.estimator.DNNLinearCombinedClassifier</strong> for wide &amp; deep models.
<strong>tf.estimator.LinearClassifier</strong> for classifiers based on linear models.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">classifier</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">estimator</span><span class="p">.</span><span class="nc">DNNClassifier</span><span class="p">(</span>
    <span class="n">feature_columns</span><span class="o">=</span><span class="n">my_feature_columns</span><span class="p">,</span><span class="c1"># Two hidden layers of 30 and 10 nodes respectively.
</span>    <span class="n">hidden_units</span><span class="o">=</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span><span class="c1"># The model must choose between 3 classes.
</span>    <span class="n">n_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">classifier</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">input_fn</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="nf">input_fn</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="n">steps</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">eval_result</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">input_fn</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="nf">input_fn</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">test_y</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span>
    <span class="n">input_fn</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="nf">input_fn</span><span class="p">(</span><span class="n">predict_x</span><span class="p">))</span></code></pre></figure>

<h3 id="tf-keras">TF Keras</h3>
<p>Keras is a high level set of estimators, ready to use. 
It requires</p>
<ul>
  <li>Model - tf.keras.Sequential()</li>
  <li>Type of layers, layers.Dense(64, activation=’relu’), it takes
    <ul>
      <li>activation</li>
      <li>kernel_regularizer, tf.keras.regularizers.l1(0.01)</li>
      <li>bias_regularizer</li>
    </ul>
  </li>
  <li>tf.keras.Model.compile , it takes
    <ul>
      <li>optimizer</li>
      <li>loss</li>
      <li>metrics</li>
    </ul>
  </li>
  <li>Fit data - model.fit()
    <ul>
      <li>epochs</li>
      <li>batch_size</li>
      <li>validation_data</li>
    </ul>
  </li>
  <li>Evaluate - model.evaluate(dataset)</li>
  <li>Predict - model.predict(data, batch_size=32)</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">))</span>
<span class="ow">or</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">activations</span><span class="p">.</span><span class="n">relu</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span>
              <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">categorical_crossentropy</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">Accuracy</span><span class="p">])</span>

<span class="c1">### Fit and run validation
</span><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<span class="n">val_labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">))</span>

<span class="c1">### or just batch up before putting in fit.
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_tensor_slices</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> 

<span class="c1">### Evaluate and predict
# With Numpy arrays
</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="c1"># With a Dataset
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_tensor_slices</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span></code></pre></figure>

<h3 id="declarative-approach-take-tensor-return-tensor">Declarative approach, take tensor, return tensor.</h3>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,))</span>  <span class="c1"># Returns an input placeholder
# A layer instance is callable on a tensor, and returns a tensor.
</span><span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">predictions</span><span class="p">)</span>
<span class="c1"># The compile step specifies the training configuration.
</span><span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">RMSprop</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span>
              <span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">categorical_crossentropy</span><span class="sh">'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">])</span>
<span class="c1"># Trains for 5 epochs
</span><span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span></code></pre></figure>

<h3 id="callbacks-in-running">Callbacks in running</h3>
<p>tf.keras.callbacks.ModelCheckpoint: Save checkpoints of your model at regular intervals.
tf.keras.callbacks.LearningRateScheduler: Dynamically change the learning rate.
tf.keras.callbacks.EarlyStopping: Interrupt training when validation performance has stopped improving.
tf.keras.callbacks.TensorBoard: Monitor the model’s behavior using TensorBoard.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
  <span class="c1"># Interrupt training if `val_loss` stops improving for over 2 epochs
</span>  <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span><span class="p">),</span>
  <span class="c1"># Write TensorBoard logs to `./logs` directory
</span>  <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="sh">'</span><span class="s">./logs</span><span class="sh">'</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">))</span></code></pre></figure>

<h3 id="save--reload">Save &amp; Reload</h3>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Recreate the exact same model, including weights and optimizer.
</span><span class="n">model</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">'</span><span class="s">my_model.h5</span><span class="sh">'</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="sh">'</span><span class="s">my_model.h5</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Save only model to json or yaml
</span><span class="n">json_string</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">to_json</span><span class="p">()</span>
<span class="n">fresh_model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">model_from_json</span><span class="p">(</span><span class="n">json_string</span><span class="p">)</span>
<span class="n">yaml_string</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">to_yaml</span><span class="p">()</span>
<span class="n">fresh_model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">model_from_yaml</span><span class="p">(</span><span class="n">yaml_string</span><span class="p">)</span>

<span class="c1"># Save weights 
</span><span class="n">model</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="sh">'</span><span class="s">./weights/my_model</span><span class="sh">'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">load_weights</span><span class="p">(</span><span class="sh">'</span><span class="s">./weights/my_model</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Distributed startegy
</span><span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="nc">MirroredStrategy</span><span class="p">()</span>
<span class="k">with</span> <span class="n">strategy</span><span class="p">.</span><span class="nf">scope</span><span class="p">():</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">binary_crossentropy</span><span class="sh">'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">summary</span><span class="p">()</span>

<span class="c1"># Display plot model
</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="sh">'</span><span class="s">multi_input_and_output_model.png</span><span class="sh">'</span><span class="p">,</span> <span class="n">show_shapes</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<h3 id="data-preprocess">Data preprocess.</h3>

<p><strong>TF Logging</strong> - It has four logging options,DEBUG,INFO ,WARNING, ERROR. tf.logging.set_verbosity(tf.logging.ERROR)</p>

<p><strong>Tensors</strong> : One number, vector, matrix etc are are form of tensor. Increase in dimension results are stored in tensors. How would you store 10 matrix. You will think array of matrix, and that variable is called tensor.</p>

<p>Tensor flow formally gives two packages, one to deal with Graph and another to run computation on graph (sessions).</p>

<p><strong>Computational Graph</strong> - Graph is same old neural network graph each node in graph has some purpose(variable,computation,placeholder), input and output. It’s a data strucutre well defined in TF.</p>

<p>Advantage of using graph- portability (Export and share), Easy to understand, parallelism,</p>

<p>Following are the component of Computational Graph.
Variable, Placeholders, contants, operation, graph, session.</p>

<p>Compared to numpy array they don’t allocate memory in starting. For ex.  a = tf.zeros(int(le12),int(le12)) will just form a shape not the actual allocation of memory. It will only allocate memory when it is executed.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
  <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">session</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">constant</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">a</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">constant</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">b</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">prod</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">multiply</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">Multiply</span><span class="sh">"</span><span class="p">)</span>
    <span class="nb">sum</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">Sum</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">divide</span><span class="p">(</span><span class="n">prod</span><span class="p">,</span><span class="nb">sum</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">Divide</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">out</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">Out</span><span class="p">)</span></code></pre></figure>

<h3 id="how-the-graph-component-looks-in-code">How the Graph component looks in Code.</h3>
<p>Here is very nice explanation from one of the blog.
https://medium.com/@d3lm/understand-tensorflow-by-mimicking-its-api-from-scratch-faa55787170d</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="k">class</span> <span class="nc">Graph</span><span class="p">():</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
    <span class="n">self</span><span class="p">.</span><span class="n">operations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">self</span><span class="p">.</span><span class="n">placeholders</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">self</span><span class="p">.</span><span class="n">variables</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">self</span><span class="p">.</span><span class="n">constants</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">as_default</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">_default_graph</span>
    <span class="n">_default_graph</span> <span class="o">=</span> <span class="n">self</span>

  <span class="p">...</span><span class="bp">...</span>

  <span class="k">class</span> <span class="nc">Operation</span><span class="p">():</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_nodes</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">self</span><span class="p">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
    <span class="n">self</span><span class="p">.</span><span class="n">output</span> <span class="o">=</span> <span class="bp">None</span>
    
    <span class="c1"># Append operation to the list of operations of the default graph
</span>    <span class="n">_default_graph</span><span class="p">.</span><span class="n">operations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">self</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
    <span class="k">pass</span>

  <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
    <span class="k">pass</span>

  <span class="p">...</span><span class="bp">...</span>

  <span class="k">class</span> <span class="nc">add</span><span class="p">(</span><span class="n">BinaryOperation</span><span class="p">):</span>
  <span class="sh">"""</span><span class="s">
  Computes a + b, element-wise
  </span><span class="sh">"""</span>
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>

  <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">upstream_grad</span><span class="p">):</span>
    <span class="k">raise</span> <span class="nb">NotImplementedError</span>
  <span class="c1"># and so on for other operators.
</span>
  <span class="k">class</span> <span class="nc">Placeholder</span><span class="p">():</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
    <span class="n">self</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">_default_graph</span><span class="p">.</span><span class="n">placeholders</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">self</span><span class="p">)</span>

  <span class="p">....</span><span class="bp">...</span>
  <span class="c1"># constant can be inputs/labels as they do not changes
</span>  <span class="k">class</span> <span class="nc">Constant</span><span class="p">():</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">self</span><span class="p">.</span><span class="n">__value</span> <span class="o">=</span> <span class="n">value</span>
    <span class="n">_default_graph</span><span class="p">.</span><span class="n">constants</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">self</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">__value</span>

  <span class="nd">@value.setter</span>
  <span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sh">"</span><span class="s">Cannot reassign value.</span><span class="sh">"</span><span class="p">)</span>

  <span class="p">....</span><span class="bp">...</span>
  <span class="c1"># Varibale changes in run of graph
</span>  <span class="k">class</span> <span class="nc">Variable</span><span class="p">():</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">initial_value</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">self</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">initial_value</span>
    <span class="n">_default_graph</span><span class="p">.</span><span class="n">variables</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">self</span><span class="p">)</span>
  <span class="p">.........</span><span class="bp">...</span>

  <span class="c1"># Visit and compute graph on topolgical order DFS.
</span>  <span class="k">def</span> <span class="nf">topology_sort</span><span class="p">(</span><span class="n">operation</span><span class="p">):</span>
    <span class="n">ordering</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">visited_nodes</span> <span class="o">=</span> <span class="nf">set</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">recursive_helper</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
      <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">Operation</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">input_node</span> <span class="ow">in</span> <span class="n">node</span><span class="p">.</span><span class="n">input_nodes</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">input_node</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">visited_nodes</span><span class="p">:</span>
            <span class="nf">recursive_helper</span><span class="p">(</span><span class="n">input_node</span><span class="p">)</span>

      <span class="n">visited_nodes</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
      <span class="n">ordering</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

    <span class="c1"># start recursive depth-first search
</span>    <span class="nf">recursive_helper</span><span class="p">(</span><span class="n">operation</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ordering</span>

  <span class="p">..............</span><span class="bp">...</span>
  <span class="k">class</span> <span class="nc">Session</span><span class="p">():</span>
  <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">operation</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{}):</span>
    <span class="n">nodes_sorted</span> <span class="o">=</span> <span class="nf">topology_sort</span><span class="p">(</span><span class="n">operation</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes_sorted</span><span class="p">:</span>
      <span class="k">if</span> <span class="nf">type</span><span class="p">(</span><span class="n">node</span><span class="p">)</span> <span class="o">==</span> <span class="n">Placeholder</span><span class="p">:</span>
        <span class="n">node</span><span class="p">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">feed_dict</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
      <span class="k">elif</span> <span class="nf">type</span><span class="p">(</span><span class="n">node</span><span class="p">)</span> <span class="o">==</span> <span class="n">Variable</span> <span class="ow">or</span> <span class="nf">type</span><span class="p">(</span><span class="n">node</span><span class="p">)</span> <span class="o">==</span> <span class="n">Constant</span><span class="p">:</span>
        <span class="n">node</span><span class="p">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">node</span><span class="p">.</span><span class="n">value</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">node</span><span class="p">.</span><span class="n">output</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">node</span><span class="p">.</span><span class="n">input_nodes</span><span class="p">]</span>
        <span class="n">node</span><span class="p">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">node</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">operation</span><span class="p">.</span><span class="n">output</span></code></pre></figure>

<h3 id="important-function-used-in-andrews-ng-course">Important Function used in Andrews NG Course.</h3>
<ul>
  <li>tf.nn.conv2d(X,W, strides = [1,s,s,1], padding = ‘SAME’) – convolution layer</li>
  <li>tf.nn.max_pool(A, ksize = [1,f,f,1], strides = [1,s,s,1], padding = ‘SAME’) - max pool layer</li>
  <li>tf.nn.relu(Z) - element wise relu</li>
  <li>tf.contrib.layers.flatten(P) – flattens the multidimensional into desire dimension</li>
  <li>tf.contrib.layers.fully_connected(F, num_outputs) – Create fully connected layer from F to num_outputs</li>
  <li>tf.nn.softmax_cross_entropy_with_logits(logits = Z, labels = Y) –Calculate cost.</li>
  <li>tf.reduce_mean – Calculate mean of all example cost.</li>
  <li>Valid vs same pad, same brings add extra padding in case if needed, valid doesn’t consider edge to apply filter. (https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t)</li>
</ul>

<h3 id="learning-on-mnist">Learning on MNIST</h3>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="p">.</span><span class="nf">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span></code></pre></figure>

            </article>

            <section class="share">
    <h3>Share</h3>
    <a aria-label="Share on Twitter" href="https://twitter.com/intent/tweet?text=&quot;&quot;%20http://localhost:4000/Machine-Learning-TensorFlow/%20via%20&#64;&hashtags=Machine Learning,"
    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Share on Twitter">
        <svg class="icon icon-twitter"><use xlink:href="#icon-twitter"></use></svg>
    </a>
    <a aria-label="Share on Facebook"href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/Machine-Learning-TensorFlow/"
    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;" title="Share on Facebook">
        <svg class="icon icon-facebook"><use xlink:href="#icon-facebook"></use></svg>
    </a>
    <a aria-label="Share on Google Plus" href="https://plus.google.com/share?url=http://localhost:4000/Machine-Learning-TensorFlow/"
    onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;" title="Share on Google+">
        <svg class="icon icon-google-plus"><use xlink:href="#icon-google-plus"></use></svg>
    </a>
</section>
            <section class="share">
                <div class="fb-comments" data-href="http://localhost:4000/Machine-Learning-TensorFlow/"></div>
            </section>
            <section class="author" itemprop="author">
    <div class="details" itemscope itemtype="http://schema.org/Person">
        <img itemprop="image" class="img-rounded" src="/assets/img/blog-author.jpg" alt="">
        <p class="def">Author</p>
        <h3 class="name">
            <a itemprop="name" href="https://plus.google.com/+/posts">Sanjay Patel</a>
        </h3>
        <p class="desc">Developer at IBM</p>
        <p><a itemprop="email" class="email" href="mailto:sanjaypatel2525@yahoo.com">sanjaypatel2525@yahoo.com</a></p>
        <!--<p><a itemprop="github" class="github" href="https://github.com/">github.com/</a></p>-->
    </div>
</section>

            <footer>
    <p>Made with <a href="http://jekyllrb.com/" target="_blank">Jekyll</a></p>
</footer>
<script src="/assets/js/main.js"></script>
            <div id="fb-root"></div>
        </section>
    </body>
    
    <script>(function(d, s, id) {
        var js, fjs = d.getElementsByTagName(s)[0];
        if (d.getElementById(id)) return;
        js = d.createElement(s); js.id = id;
        js.src = "//connect.facebook.net/en_GB/all.js#xfbml=1&appId=207343132703435";
        fjs.parentNode.insertBefore(js, fjs);
        }(document, "script", "facebook-jssdk"));</script>
</html>
